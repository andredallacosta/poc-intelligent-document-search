# ADR 001 — Migração para PostgreSQL + pgvector com Multi-tenancy

## Status

Aceito ✅ (Atualizado após discussão técnica)

## Contexto

O sistema atual (v2.0) utiliza **ChromaDB + Redis** com Clean Architecture. Precisamos evoluir para:

* **Multi-tenancy**: Suportar múltiplas prefeituras com controle de quotas
* **Auditoria completa**: Histórico de conversas e consumo de tokens por usuário/prefeitura
* **Escalabilidade**: Até 50 usuários iniciais, preparado para crescimento
* **Custo otimizado**: Orçamento total de **R$ 500/mês** (infra + IA + front + backend)
* **Documentos globais**: Compartilhados entre prefeituras (não segregados)
* **Manter Clean Architecture**: Preservar estrutura atual com Domain-Driven Design

### Decisões de Infraestrutura

* **DigitalOcean** em vez de AWS (40% mais barato)
* **PostgreSQL Managed** + **Droplet 2GB** + **Redis local**
* **Custo estimado**: ~$32/mês infra, sobra $68/mês para IA

## Decisão

* **Migrar ChromaDB → PostgreSQL + pgvector** mantendo mesma interface de repositório
* **Manter Redis** para sessões ativas (cache, não persistente)
* **Adicionar entidades**: Prefeitura, Usuario (multi-tenancy)
* **Preservar entidades atuais**: Document, ChatSession, Message, DocumentChunk
* A estrutura inicial conterá:

  * **Tabela de prefeituras**: quotas e consumo de tokens.
  * **Tabela de usuários**: autenticados, vinculados a uma prefeitura.
  * **Tabela de documentos**: documentos gerais, com link para armazenamento em S3.
  * **Tabela de embeddings**: chunks de documentos vetorizados para busca semântica.
  * **Tabela de conversas**: histórico de interações, perguntas, respostas e tokens consumidos.
* Armazenamento de arquivos originais será feito no **Amazon S3**, com apenas os metadados no PostgreSQL.
* Monitoramento de consumo por prefeitura será feito via agregação de histórico de conversas.

## Esquema PostgreSQL + Clean Architecture

```sql
-- Extensão para vetores
CREATE EXTENSION IF NOT EXISTS vector;

-- Multi-tenancy
CREATE TABLE prefeitura (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    nome TEXT NOT NULL,
    quota_tokens INT NOT NULL DEFAULT 10000,
    tokens_consumidos INT DEFAULT 0,
    ativo BOOLEAN DEFAULT true,
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

CREATE TABLE usuario (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    prefeitura_id UUID REFERENCES prefeitura(id),
    nome TEXT NOT NULL,
    email TEXT UNIQUE NOT NULL,
    senha_hash TEXT, -- NULL até implementar auth
    ativo BOOLEAN DEFAULT true,
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

-- Documentos (mantém estrutura atual)
CREATE TABLE documento (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    titulo TEXT NOT NULL,
    conteudo TEXT NOT NULL,
    caminho_arquivo TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

CREATE TABLE documento_chunk (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    documento_id UUID REFERENCES documento(id) ON DELETE CASCADE,
    conteudo TEXT NOT NULL,
    indice_chunk INT NOT NULL,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW()
);

-- Embeddings com pgvector
CREATE TABLE documento_embedding (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    chunk_id UUID REFERENCES documento_chunk(id) ON DELETE CASCADE,
    embedding VECTOR(1536), -- OpenAI text-embedding-3-small
    criado_em TIMESTAMP DEFAULT NOW()
);

-- Sessões de chat (mantém estrutura atual)
CREATE TABLE chat_session (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    usuario_id UUID REFERENCES usuario(id), -- NULL para sessões anônimas (temporário)
    ativo BOOLEAN DEFAULT true,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

CREATE TABLE message (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID REFERENCES chat_session(id) ON DELETE CASCADE,
    role TEXT NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
    conteudo TEXT NOT NULL,
    tipo_mensagem TEXT DEFAULT 'text',
    referencias_documento JSONB DEFAULT '[]',
    tokens_usados INT DEFAULT 0,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW()
);

-- Índices para performance
CREATE INDEX idx_documento_embedding_vector ON documento_embedding USING ivfflat (embedding vector_cosine_ops);
CREATE INDEX idx_message_session_id ON message(session_id);
CREATE INDEX idx_message_created_at ON message(criado_em);
CREATE INDEX idx_usuario_prefeitura ON usuario(prefeitura_id);
```

## Estratégia de Migração

### Fases da Migração

1. **Preservar Clean Architecture**: Manter interfaces de repositório existentes
2. **Migração incremental**: PostgreSQL substitui ChromaDB gradualmente
3. **Multi-tenancy opcional**: Sistema funciona com/sem usuário logado
4. **Backward compatibility**: APIs existentes continuam funcionando

### ORM vs SQL Puro

**Decisão**: Usar **SQLAlchemy Core** (não ORM completo)

* **Vantagem**: Controle total sobre queries, performance otimizada para pgvector
* **Desvantagem**: Mais código manual, mas mantém simplicidade
* **Alternativa considerada**: Tortoise ORM (async), mas adiciona complexidade desnecessária

### Análise de Limitações: ChromaDB → pgvector

#### **Fluxo de Inserção de Documentos Analisado**

**Fluxo atual identificado**:

1. `DocumentService.create_document()` - Verificação básica de duplicação por `metadata.source`
2. `TextChunker.chunk_document_content()` - Processamento em chunks com contextualização
3. `DocumentService.add_chunks_to_document()` - Associação de chunks ao documento
4. `VectorRepository.add_chunk_embedding()` - Inserção individual de embeddings no ChromaDB

#### **Limitações Identificadas e Soluções**

**1. Controle de Duplicação Insuficiente**

* **Problema**: Verificação apenas por `metadata.source` é frágil
* **Solução pgvector**: Múltiplos critérios (source + título similar + hash do arquivo)
* **Implementação**: Constraints UNIQUE + índices GIN para busca fuzzy de títulos

**2. Performance de Inserção Batch**

* **ChromaDB**: Otimizado nativamente para `collection.add(ids=[], embeddings=[])`
* **pgvector**: Requer otimização manual com `COPY` (10x mais rápido que INSERT)
* **Impacto**: ~2x mais lento que ChromaDB, mas aceitável para 50 usuários

**3. Consistência de Dados**

* **ChromaDB**: Sem transações, possível inconsistência entre documento e embeddings
* **pgvector**: Transações ACID garantem atomicidade completa
* **Vantagem**: Rollback automático se qualquer etapa falhar

#### **Melhorias Implementadas**

**Schema otimizado para duplicação**:

```sql
-- Constraints para evitar duplicação
CONSTRAINT unique_source UNIQUE (metadata->>'source'),
CONSTRAINT unique_file_hash UNIQUE (file_hash) WHERE file_hash IS NOT NULL

-- Índices para busca rápida
CREATE INDEX idx_documento_titulo_similarity ON documento USING gin(titulo gin_trgm_ops);
CREATE INDEX idx_documento_file_hash ON documento (file_hash);
```

**Verificação robusta de duplicação**:

* Por source (exato)
* Por título (similaridade fuzzy com threshold 0.9)
* Por hash SHA256 do arquivo (conteúdo idêntico)

**Inserção batch otimizada**:

* Uso de `COPY` para embeddings em lote
* Transações para consistência documento + chunks + embeddings
* Rollback automático em caso de falha

## Consequências

### Positivas

* **Custo 40% menor** com DigitalOcean vs AWS
* **Embeddings + dados relacionais** em um só lugar (simplicidade)
* **Clean Architecture preservada** (baixo impacto na migração)
* **Multi-tenancy preparado** para crescimento futuro
* **Auditoria completa** de tokens e conversas
* **pgvector suficiente** para 50 usuários iniciais
* **Controle de duplicação robusto** (múltiplos critérios vs source apenas)
* **Transações ACID** garantem consistência documento + embeddings
* **Facilidade de adição de novos documentos** com verificação automática
* **Joins nativos** para filtros complexos (usuário + prefeitura + documento)

### Negativas

* **Migração manual** de ChromaDB para PostgreSQL
* **Complexidade adicional** com multi-tenancy (mas necessária)
* **Performance inserção batch** ~2x mais lenta que ChromaDB (mas aceitável)
* **Dependência PostgreSQL** para tudo (embeddings + dados)
* **Necessidade de otimização manual** para queries pgvector (vs ChromaDB automático)

## Alternativas Consideradas

1. **Manter ChromaDB + PostgreSQL híbrido**
   * Vantagem: Performance máxima para embeddings
   * Desvantagem: Complexidade de manter 2 bancos, custos extras

2. **SQLAlchemy ORM completo**
   * Vantagem: Menos código SQL manual
   * Desvantagem: Overhead desnecessário, queries pgvector complexas

3. **Tortoise ORM (async nativo)**
   * Vantagem: Async nativo, sintaxe Django-like
   * Desvantagem: Menos controle sobre pgvector, curva de aprendizado

**Decisão final**: PostgreSQL + pgvector + SQLAlchemy Core + DigitalOcean como melhor equilíbrio custo/performance/simplicidade.

## Pontos Críticos de Migração Identificados

### **✅ CRÍTICOS CORRIGIDOS**

**1. Container DI Hardcoded** ✅

* **Problema**: `get_vector_repository()` retorna `ChromaVectorRepository` (tipo concreto)
* **Solução**: ✅ Corrigido - retorna `VectorRepository` (interface)
* **Status**: Permite troca transparente de implementação

**2. Scripts de Ingestão Ausentes** ✅

* **Problema**: `pyproject.toml` referencia scripts inexistentes (`ingest-documents`, `migrate-data`)
* **Solução**: ✅ Criados `scripts/ingest_documents.py` e `scripts/migrate_data.py`
* **Status**: Scripts funcionais com DI correto

**3. Startup Hardcoded** ✅

* **Problema**: `main.py` testa conexão ChromaDB diretamente
* **Solução**: ✅ Usa interface `VectorRepository` para teste
* **Status**: Funciona com qualquer implementação

**4. DocumentRepository Concreto** ✅

* **Problema**: Só existe interface, sem implementação
* **Solução**: ✅ Criado `MemoryDocumentRepository` (temporário)
* **Status**: DocumentService funcional

**5. Dependências PostgreSQL** ✅

* **Problema**: `pyproject.toml` não inclui `asyncpg`, `sqlalchemy`, `psycopg2`
* **Solução**: ✅ Adicionadas dependências PostgreSQL + Alembic
* **Status**: Pronto para conectar PostgreSQL

### **⚠️ IMPLEMENTAÇÕES TEMPORÁRIAS (REMOVER NA MIGRAÇÃO)**

**Arquivos criados apenas para desenvolvimento - DEVEM SER REMOVIDOS:**

**1. `infrastructure/repositories/memory_document_repository.py`** 🗑️

* **Motivo**: Implementação temporária para DocumentRepository ausente
* **Substituto**: `PostgresDocumentRepository` + `PostgresDocumentChunkRepository`
* **Quando remover**: Após implementar repositórios PostgreSQL
* **Impacto**: Arquivo completo pode ser deletado

**2. Container DI - Métodos temporários** 🔧

```python
# interface/dependencies/container.py - REMOVER após migração:
def get_document_repository(self) -> DocumentRepository:
    return MemoryDocumentRepository()  # ← TEMPORÁRIO

def get_document_chunk_repository(self) -> DocumentChunkRepository:
    return MemoryDocumentChunkRepository()  # ← TEMPORÁRIO
```

**3. Dependência ChromaDB** 🗑️

```python
# pyproject.toml - REMOVER após migração:
"chromadb>=0.4.0",  # ← Não será mais necessário

# interface/dependencies/container.py - REMOVER:
from infrastructure.external.chroma_client import ChromaClient
from infrastructure.repositories.chroma_vector_repository import ChromaVectorRepository

def get_chroma_client(self) -> ChromaClient:  # ← REMOVER MÉTODO COMPLETO
def get_vector_repository(self) -> VectorRepository:
    return ChromaVectorRepository(...)  # ← SUBSTITUIR por PostgresVectorRepository
```

### **📋 CHECKLIST DE LIMPEZA PÓS-MIGRAÇÃO**

**Arquivos para DELETAR:**

* [ ] `infrastructure/repositories/memory_document_repository.py`
* [ ] `infrastructure/external/chroma_client.py`
* [ ] `infrastructure/repositories/chroma_vector_repository.py`
* [ ] `storage/vector_db/` (diretório ChromaDB)

**Dependências para REMOVER do pyproject.toml:**

* [ ] `"chromadb>=0.4.0"`
* [ ] Imports ChromaDB no container.py

**Métodos Container para SUBSTITUIR:**

* [ ] `get_chroma_client()` → DELETAR
* [ ] `get_vector_repository()` → usar `PostgresVectorRepository`
* [ ] `get_document_repository()` → usar `PostgresDocumentRepository`
* [ ] `get_document_chunk_repository()` → usar `PostgresDocumentChunkRepository`

## 🚀 Plano de Migração PostgreSQL

### **Fase 1: Configuração Base PostgreSQL**

1. [ ] Criar configuração de conexão PostgreSQL (`infrastructure/database/connection.py`)
2. [ ] Configurar SQLAlchemy Core com asyncpg
3. [ ] Criar models SQLAlchemy para todas as tabelas
4. [ ] Configurar Alembic para migrations
5. [ ] Criar migration inicial com schema completo

### **Fase 2: Entidades Multi-tenancy**

1. [ ] Criar entidade `Prefeitura` no Domain
2. [ ] Criar entidade `Usuario` no Domain  
3. [ ] Atualizar entidades existentes para suportar multi-tenancy
4. [ ] Criar value objects para multi-tenancy (PrefeituraId, UsuarioId)

### **Fase 3: Repositórios PostgreSQL**

1. [ ] Implementar `PostgresDocumentRepository`
2. [ ] Implementar `PostgresDocumentChunkRepository`
3. [ ] Implementar `PostgresVectorRepository` com pgvector
4. [ ] Implementar `PostgresPrefeituraRepository`
5. [ ] Implementar `PostgresUsuarioRepository`
6. [ ] Implementar `PostgresSessionRepository` (substituir Redis)

### **Fase 4: Atualização Container DI**

1. [ ] Adicionar configuração PostgreSQL no Container
2. [ ] Substituir métodos temporários por implementações PostgreSQL
3. [ ] Configurar connection pooling e transações
4. [ ] Atualizar dependency injection para FastAPI

### **Fase 5: Migração de Dados e Testes**

1. [ ] Testar todos os repositórios PostgreSQL
2. [ ] Atualizar scripts de ingestão para PostgreSQL
3. [ ] Carregar documentos reais no PostgreSQL
4. [ ] Testar funcionalidades completas
5. [ ] Validar performance pgvector vs ChromaDB

### **Fase 6: Limpeza (EXECUTAR APENAS APÓS TESTES COMPLETOS)**

1. [ ] Deletar arquivos temporários (conforme checklist acima)
2. [ ] Remover dependências desnecessárias do pyproject.toml
3. [ ] Limpar imports não utilizados
4. [ ] Atualizar documentação final
5. [ ] Commit final da migração

### **🎯 Critérios de Sucesso da Migração**

* [ ] Sistema funciona 100% com PostgreSQL

* [ ] Todos os testes passam
* [ ] Performance aceitável (≤2x mais lenta que ChromaDB)
* [ ] Multi-tenancy implementado e testado
* [ ] Documentação atualizada
* [ ] Código limpo (sem implementações temporárias)

### **✅ PONTOS FORTES (Facilitam migração)**

* **Clean Architecture**: Interfaces bem definidas permitem troca de implementação
* **Dependency Injection**: Container permite substituição transparente
* **Entidades Domain**: Independentes de infraestrutura
* **Use Cases**: Não dependem de implementações específicas
