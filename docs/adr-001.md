# ADR 001 ‚Äî Migra√ß√£o para PostgreSQL + pgvector com Multi-tenancy

## Status

Aceito ‚úÖ (Atualizado ap√≥s discuss√£o t√©cnica)

## Contexto

O sistema atual (v2.0) utiliza **ChromaDB + Redis** com Clean Architecture. Precisamos evoluir para:

* **Multi-tenancy**: Suportar m√∫ltiplas prefeituras com controle de quotas
* **Auditoria completa**: Hist√≥rico de conversas e consumo de tokens por usu√°rio/prefeitura
* **Escalabilidade**: At√© 50 usu√°rios iniciais, preparado para crescimento
* **Custo otimizado**: Or√ßamento total de **R$ 500/m√™s** (infra + IA + front + backend)
* **Documentos globais**: Compartilhados entre prefeituras (n√£o segregados)
* **Manter Clean Architecture**: Preservar estrutura atual com Domain-Driven Design

### Decis√µes de Infraestrutura

* **DigitalOcean** em vez de AWS (40% mais barato)
* **PostgreSQL Managed** + **Droplet 2GB** + **Redis local**
* **Custo estimado**: ~$32/m√™s infra, sobra $68/m√™s para IA

## Decis√£o

* **Migrar ChromaDB ‚Üí PostgreSQL + pgvector** mantendo mesma interface de reposit√≥rio
* **Manter Redis** para sess√µes ativas (cache, n√£o persistente)
* **Adicionar entidades**: Prefeitura, Usuario (multi-tenancy)
* **Preservar entidades atuais**: Document, ChatSession, Message, DocumentChunk
* A estrutura inicial conter√°:

  * **Tabela de prefeituras**: quotas e consumo de tokens.
  * **Tabela de usu√°rios**: autenticados, vinculados a uma prefeitura.
  * **Tabela de documentos**: documentos gerais, com link para armazenamento em S3.
  * **Tabela de embeddings**: chunks de documentos vetorizados para busca sem√¢ntica.
  * **Tabela de conversas**: hist√≥rico de intera√ß√µes, perguntas, respostas e tokens consumidos.
* Armazenamento de arquivos originais ser√° feito no **Amazon S3**, com apenas os metadados no PostgreSQL.
* Monitoramento de consumo por prefeitura ser√° feito via agrega√ß√£o de hist√≥rico de conversas.

## Esquema PostgreSQL + Clean Architecture

```sql
-- Extens√£o para vetores
CREATE EXTENSION IF NOT EXISTS vector;

-- Multi-tenancy
CREATE TABLE prefeitura (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    nome TEXT NOT NULL,
    quota_tokens INT NOT NULL DEFAULT 10000,
    tokens_consumidos INT DEFAULT 0,
    ativo BOOLEAN DEFAULT true,
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

CREATE TABLE usuario (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    prefeitura_id UUID REFERENCES prefeitura(id),
    nome TEXT NOT NULL,
    email TEXT UNIQUE NOT NULL,
    senha_hash TEXT, -- NULL at√© implementar auth
    ativo BOOLEAN DEFAULT true,
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

-- Documentos (mant√©m estrutura atual)
CREATE TABLE documento (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    titulo TEXT NOT NULL,
    conteudo TEXT NOT NULL,
    caminho_arquivo TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

CREATE TABLE documento_chunk (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    documento_id UUID REFERENCES documento(id) ON DELETE CASCADE,
    conteudo TEXT NOT NULL,
    indice_chunk INT NOT NULL,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW()
);

-- Embeddings com pgvector
CREATE TABLE documento_embedding (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    chunk_id UUID REFERENCES documento_chunk(id) ON DELETE CASCADE,
    embedding VECTOR(1536), -- OpenAI text-embedding-3-small
    criado_em TIMESTAMP DEFAULT NOW()
);

-- Sess√µes de chat (mant√©m estrutura atual)
CREATE TABLE chat_session (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    usuario_id UUID REFERENCES usuario(id), -- NULL para sess√µes an√¥nimas (tempor√°rio)
    ativo BOOLEAN DEFAULT true,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW(),
    atualizado_em TIMESTAMP DEFAULT NOW()
);

CREATE TABLE message (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID REFERENCES chat_session(id) ON DELETE CASCADE,
    role TEXT NOT NULL CHECK (role IN ('user', 'assistant', 'system')),
    conteudo TEXT NOT NULL,
    tipo_mensagem TEXT DEFAULT 'text',
    referencias_documento JSONB DEFAULT '[]',
    tokens_usados INT DEFAULT 0,
    metadata JSONB DEFAULT '{}',
    criado_em TIMESTAMP DEFAULT NOW()
);

-- √çndices para performance
CREATE INDEX idx_documento_embedding_vector ON documento_embedding USING ivfflat (embedding vector_cosine_ops);
CREATE INDEX idx_message_session_id ON message(session_id);
CREATE INDEX idx_message_created_at ON message(criado_em);
CREATE INDEX idx_usuario_prefeitura ON usuario(prefeitura_id);
```

## Estrat√©gia de Migra√ß√£o

### Fases da Migra√ß√£o

1. **Preservar Clean Architecture**: Manter interfaces de reposit√≥rio existentes
2. **Migra√ß√£o incremental**: PostgreSQL substitui ChromaDB gradualmente
3. **Multi-tenancy opcional**: Sistema funciona com/sem usu√°rio logado
4. **Backward compatibility**: APIs existentes continuam funcionando

### ORM vs SQL Puro

**Decis√£o**: Usar **SQLAlchemy Core** (n√£o ORM completo)

* **Vantagem**: Controle total sobre queries, performance otimizada para pgvector
* **Desvantagem**: Mais c√≥digo manual, mas mant√©m simplicidade
* **Alternativa considerada**: Tortoise ORM (async), mas adiciona complexidade desnecess√°ria

### An√°lise de Limita√ß√µes: ChromaDB ‚Üí pgvector

#### **Fluxo de Inser√ß√£o de Documentos Analisado**

**Fluxo atual identificado**:

1. `DocumentService.create_document()` - Verifica√ß√£o b√°sica de duplica√ß√£o por `metadata.source`
2. `TextChunker.chunk_document_content()` - Processamento em chunks com contextualiza√ß√£o
3. `DocumentService.add_chunks_to_document()` - Associa√ß√£o de chunks ao documento
4. `VectorRepository.add_chunk_embedding()` - Inser√ß√£o individual de embeddings no ChromaDB

#### **Limita√ß√µes Identificadas e Solu√ß√µes**

**1. Controle de Duplica√ß√£o Insuficiente**

* **Problema**: Verifica√ß√£o apenas por `metadata.source` √© fr√°gil
* **Solu√ß√£o pgvector**: M√∫ltiplos crit√©rios (source + t√≠tulo similar + hash do arquivo)
* **Implementa√ß√£o**: Constraints UNIQUE + √≠ndices GIN para busca fuzzy de t√≠tulos

**2. Performance de Inser√ß√£o Batch**

* **ChromaDB**: Otimizado nativamente para `collection.add(ids=[], embeddings=[])`
* **pgvector**: Requer otimiza√ß√£o manual com `COPY` (10x mais r√°pido que INSERT)
* **Impacto**: ~2x mais lento que ChromaDB, mas aceit√°vel para 50 usu√°rios

**3. Consist√™ncia de Dados**

* **ChromaDB**: Sem transa√ß√µes, poss√≠vel inconsist√™ncia entre documento e embeddings
* **pgvector**: Transa√ß√µes ACID garantem atomicidade completa
* **Vantagem**: Rollback autom√°tico se qualquer etapa falhar

#### **Melhorias Implementadas**

**Schema otimizado para duplica√ß√£o**:

```sql
-- Constraints para evitar duplica√ß√£o
CONSTRAINT unique_source UNIQUE (metadata->>'source'),
CONSTRAINT unique_file_hash UNIQUE (file_hash) WHERE file_hash IS NOT NULL

-- √çndices para busca r√°pida
CREATE INDEX idx_documento_titulo_similarity ON documento USING gin(titulo gin_trgm_ops);
CREATE INDEX idx_documento_file_hash ON documento (file_hash);
```

**Verifica√ß√£o robusta de duplica√ß√£o**:

* Por source (exato)
* Por t√≠tulo (similaridade fuzzy com threshold 0.9)
* Por hash SHA256 do arquivo (conte√∫do id√™ntico)

**Inser√ß√£o batch otimizada**:

* Uso de `COPY` para embeddings em lote
* Transa√ß√µes para consist√™ncia documento + chunks + embeddings
* Rollback autom√°tico em caso de falha

## Consequ√™ncias

### Positivas

* **Custo 40% menor** com DigitalOcean vs AWS
* **Embeddings + dados relacionais** em um s√≥ lugar (simplicidade)
* **Clean Architecture preservada** (baixo impacto na migra√ß√£o)
* **Multi-tenancy preparado** para crescimento futuro
* **Auditoria completa** de tokens e conversas
* **pgvector suficiente** para 50 usu√°rios iniciais
* **Controle de duplica√ß√£o robusto** (m√∫ltiplos crit√©rios vs source apenas)
* **Transa√ß√µes ACID** garantem consist√™ncia documento + embeddings
* **Facilidade de adi√ß√£o de novos documentos** com verifica√ß√£o autom√°tica
* **Joins nativos** para filtros complexos (usu√°rio + prefeitura + documento)

### Negativas

* **Migra√ß√£o manual** de ChromaDB para PostgreSQL
* **Complexidade adicional** com multi-tenancy (mas necess√°ria)
* **Performance inser√ß√£o batch** ~2x mais lenta que ChromaDB (mas aceit√°vel)
* **Depend√™ncia PostgreSQL** para tudo (embeddings + dados)
* **Necessidade de otimiza√ß√£o manual** para queries pgvector (vs ChromaDB autom√°tico)

## Alternativas Consideradas

1. **Manter ChromaDB + PostgreSQL h√≠brido**
   * Vantagem: Performance m√°xima para embeddings
   * Desvantagem: Complexidade de manter 2 bancos, custos extras

2. **SQLAlchemy ORM completo**
   * Vantagem: Menos c√≥digo SQL manual
   * Desvantagem: Overhead desnecess√°rio, queries pgvector complexas

3. **Tortoise ORM (async nativo)**
   * Vantagem: Async nativo, sintaxe Django-like
   * Desvantagem: Menos controle sobre pgvector, curva de aprendizado

**Decis√£o final**: PostgreSQL + pgvector + SQLAlchemy Core + DigitalOcean como melhor equil√≠brio custo/performance/simplicidade.

## Pontos Cr√≠ticos de Migra√ß√£o Identificados

### **‚úÖ CR√çTICOS CORRIGIDOS**

**1. Container DI Hardcoded** ‚úÖ

* **Problema**: `get_vector_repository()` retorna `ChromaVectorRepository` (tipo concreto)
* **Solu√ß√£o**: ‚úÖ Corrigido - retorna `VectorRepository` (interface)
* **Status**: Permite troca transparente de implementa√ß√£o

**2. Scripts de Ingest√£o Ausentes** ‚úÖ

* **Problema**: `pyproject.toml` referencia scripts inexistentes (`ingest-documents`, `migrate-data`)
* **Solu√ß√£o**: ‚úÖ Criados `scripts/ingest_documents.py` e `scripts/migrate_data.py`
* **Status**: Scripts funcionais com DI correto

**3. Startup Hardcoded** ‚úÖ

* **Problema**: `main.py` testa conex√£o ChromaDB diretamente
* **Solu√ß√£o**: ‚úÖ Usa interface `VectorRepository` para teste
* **Status**: Funciona com qualquer implementa√ß√£o

**4. DocumentRepository Concreto** ‚úÖ

* **Problema**: S√≥ existe interface, sem implementa√ß√£o
* **Solu√ß√£o**: ‚úÖ Criado `MemoryDocumentRepository` (tempor√°rio)
* **Status**: DocumentService funcional

**5. Depend√™ncias PostgreSQL** ‚úÖ

* **Problema**: `pyproject.toml` n√£o inclui `asyncpg`, `sqlalchemy`, `psycopg2`
* **Solu√ß√£o**: ‚úÖ Adicionadas depend√™ncias PostgreSQL + Alembic
* **Status**: Pronto para conectar PostgreSQL

### **‚ö†Ô∏è IMPLEMENTA√á√ïES TEMPOR√ÅRIAS (REMOVER NA MIGRA√á√ÉO)**

**Arquivos criados apenas para desenvolvimento - DEVEM SER REMOVIDOS:**

**1. `infrastructure/repositories/memory_document_repository.py`** üóëÔ∏è

* **Motivo**: Implementa√ß√£o tempor√°ria para DocumentRepository ausente
* **Substituto**: `PostgresDocumentRepository` + `PostgresDocumentChunkRepository`
* **Quando remover**: Ap√≥s implementar reposit√≥rios PostgreSQL
* **Impacto**: Arquivo completo pode ser deletado

**2. Container DI - M√©todos tempor√°rios** üîß

```python
# interface/dependencies/container.py - REMOVER ap√≥s migra√ß√£o:
def get_document_repository(self) -> DocumentRepository:
    return MemoryDocumentRepository()  # ‚Üê TEMPOR√ÅRIO

def get_document_chunk_repository(self) -> DocumentChunkRepository:
    return MemoryDocumentChunkRepository()  # ‚Üê TEMPOR√ÅRIO
```

**3. Depend√™ncia ChromaDB** üóëÔ∏è

```python
# pyproject.toml - REMOVER ap√≥s migra√ß√£o:
"chromadb>=0.4.0",  # ‚Üê N√£o ser√° mais necess√°rio

# interface/dependencies/container.py - REMOVER:
from infrastructure.external.chroma_client import ChromaClient
from infrastructure.repositories.chroma_vector_repository import ChromaVectorRepository

def get_chroma_client(self) -> ChromaClient:  # ‚Üê REMOVER M√âTODO COMPLETO
def get_vector_repository(self) -> VectorRepository:
    return ChromaVectorRepository(...)  # ‚Üê SUBSTITUIR por PostgresVectorRepository
```

### **üìã CHECKLIST DE LIMPEZA P√ìS-MIGRA√á√ÉO**

**Arquivos para DELETAR:**

* [ ] `infrastructure/repositories/memory_document_repository.py`
* [ ] `infrastructure/external/chroma_client.py`
* [ ] `infrastructure/repositories/chroma_vector_repository.py`
* [ ] `storage/vector_db/` (diret√≥rio ChromaDB)

**Depend√™ncias para REMOVER do pyproject.toml:**

* [ ] `"chromadb>=0.4.0"`
* [ ] Imports ChromaDB no container.py

**M√©todos Container para SUBSTITUIR:**

* [ ] `get_chroma_client()` ‚Üí DELETAR
* [ ] `get_vector_repository()` ‚Üí usar `PostgresVectorRepository`
* [ ] `get_document_repository()` ‚Üí usar `PostgresDocumentRepository`
* [ ] `get_document_chunk_repository()` ‚Üí usar `PostgresDocumentChunkRepository`

## üöÄ Plano de Migra√ß√£o PostgreSQL

### **Fase 1: Configura√ß√£o Base PostgreSQL**

1. [ ] Criar configura√ß√£o de conex√£o PostgreSQL (`infrastructure/database/connection.py`)
2. [ ] Configurar SQLAlchemy Core com asyncpg
3. [ ] Criar models SQLAlchemy para todas as tabelas
4. [ ] Configurar Alembic para migrations
5. [ ] Criar migration inicial com schema completo

### **Fase 2: Entidades Multi-tenancy**

1. [ ] Criar entidade `Prefeitura` no Domain
2. [ ] Criar entidade `Usuario` no Domain  
3. [ ] Atualizar entidades existentes para suportar multi-tenancy
4. [ ] Criar value objects para multi-tenancy (PrefeituraId, UsuarioId)

### **Fase 3: Reposit√≥rios PostgreSQL**

1. [ ] Implementar `PostgresDocumentRepository`
2. [ ] Implementar `PostgresDocumentChunkRepository`
3. [ ] Implementar `PostgresVectorRepository` com pgvector
4. [ ] Implementar `PostgresPrefeituraRepository`
5. [ ] Implementar `PostgresUsuarioRepository`
6. [ ] Implementar `PostgresSessionRepository` (substituir Redis)

### **Fase 4: Atualiza√ß√£o Container DI**

1. [ ] Adicionar configura√ß√£o PostgreSQL no Container
2. [ ] Substituir m√©todos tempor√°rios por implementa√ß√µes PostgreSQL
3. [ ] Configurar connection pooling e transa√ß√µes
4. [ ] Atualizar dependency injection para FastAPI

### **Fase 5: Migra√ß√£o de Dados e Testes**

1. [ ] Testar todos os reposit√≥rios PostgreSQL
2. [ ] Atualizar scripts de ingest√£o para PostgreSQL
3. [ ] Carregar documentos reais no PostgreSQL
4. [ ] Testar funcionalidades completas
5. [ ] Validar performance pgvector vs ChromaDB

### **Fase 6: Limpeza (EXECUTAR APENAS AP√ìS TESTES COMPLETOS)**

1. [ ] Deletar arquivos tempor√°rios (conforme checklist acima)
2. [ ] Remover depend√™ncias desnecess√°rias do pyproject.toml
3. [ ] Limpar imports n√£o utilizados
4. [ ] Atualizar documenta√ß√£o final
5. [ ] Commit final da migra√ß√£o

### **üéØ Crit√©rios de Sucesso da Migra√ß√£o**

* [ ] Sistema funciona 100% com PostgreSQL

* [ ] Todos os testes passam
* [ ] Performance aceit√°vel (‚â§2x mais lenta que ChromaDB)
* [ ] Multi-tenancy implementado e testado
* [ ] Documenta√ß√£o atualizada
* [ ] C√≥digo limpo (sem implementa√ß√µes tempor√°rias)

### **‚úÖ PONTOS FORTES (Facilitam migra√ß√£o)**

* **Clean Architecture**: Interfaces bem definidas permitem troca de implementa√ß√£o
* **Dependency Injection**: Container permite substitui√ß√£o transparente
* **Entidades Domain**: Independentes de infraestrutura
* **Use Cases**: N√£o dependem de implementa√ß√µes espec√≠ficas
