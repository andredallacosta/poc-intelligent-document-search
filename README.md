# ğŸ” Intelligent Document Search

> Transform your documents into a searchable knowledge base powered by AI

A proof-of-concept that ingests various document formats (PDF, DOCX, URLs) and enables semantic search using vector embeddings and ChromaDB.

## âœ¨ Features

- ğŸ“„ **Multi-format support**: PDF, DOCX, and web content
- ğŸ§  **Semantic search**: Find content by meaning, not just keywords
- âš¡ **Fast retrieval**: ChromaDB vector database for efficient similarity search
- ğŸ¤– **OpenAI embeddings**: Powered by `text-embedding-3-small`
- ğŸ”§ **Smart chunking**: Intelligent text splitting with context preservation

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API key

### Installation

1. Clone the repository

```bash
git clone https://github.com/andredallacosta/poc-intelligent-document-search.git
cd poc-intelligent-document-search
```

2. Install dependencies

```bash
pip install -r requirements.txt
```

3. Set up environment variables

```bash
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

### Usage

1. **Add documents** to the `documents/` folder

2. **Ingest documents** into the vector database

```bash
python src/ingest.py
```

3. **Search your documents**

```bash
python src/query.py
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py      # Document processing pipeline
â”‚   â”œâ”€â”€ query.py       # Semantic search interface
â”‚   â”œâ”€â”€ embedder.py    # OpenAI embedding generation
â”‚   â””â”€â”€ chunker.py     # Text chunking logic
â”œâ”€â”€ documents/         # Place your documents here
â”œâ”€â”€ data/             # ChromaDB storage (auto-created)
â””â”€â”€ requirements.txt  # Dependencies
```

## ğŸ›  How It Works

1. **Document Parsing**: Extracts text from PDFs, Word docs, and web pages
2. **Smart Chunking**: Breaks text into 300-500 token chunks with overlap
3. **Vector Embeddings**: Converts chunks to numerical representations using OpenAI
4. **Storage**: Saves embeddings in ChromaDB for fast retrieval
5. **Semantic Search**: Finds relevant content based on meaning similarity

## ğŸ’¡ Example

```python
from src.query import DocumentQuery

query = DocumentQuery()
results = query.search("How to write a formal letter?", n_results=3)

for result in results:
    print(f"Source: {result['metadata']['source']}")
    print(f"Text: {result['text'][:200]}...")
    print(f"Similarity: {1 - result['distance']:.3f}")
```

## ğŸ”§ Tech Stack

- **Vector Database**: ChromaDB (local, SQLite-based)
- **Embeddings**: OpenAI text-embedding-3-small
- **Text Processing**: LangChain, unstructured, python-docx
- **Web Scraping**: trafilatura

## ğŸ“‹ Supported Formats

- ğŸ“„ PDF files
- ğŸ“ Microsoft Word (.docx)
- ğŸŒ Web pages (URLs)

## ğŸ¯ Use Cases

- Legal document research
- Technical documentation search
- Knowledge base creation
- Content discovery
- Research assistance

## ğŸ“ˆ Cost Efficiency

Using OpenAI's most cost-effective embedding model:

- **$0.02 per 1M tokens** (text-embedding-3-small)
- Typical document: ~$0.001-0.01 to process

## ğŸ¤ Contributing

This is a proof-of-concept project. Feel free to fork and experiment!

## ğŸ“„ License

MIT License - feel free to use this for your own projects.

---

<p align="center">
  <strong>Built with â¤ï¸ for intelligent document discovery</strong>
</p>
